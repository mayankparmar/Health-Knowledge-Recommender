# PDF Data Extraction and Annotation Configuration
# LOCAL LLM Example - LlamaCPP (GGUF Models)
# Health Knowledge Recommender Project

# Use GGUF quantized models with llama.cpp
# Download models from HuggingFace (search for GGUF files)
# Example: https://huggingface.co/TheBloke

data_paths:
  fast_stages: data/wp-01/fast-stages.json
  adl_file: data/wp-01/[Katz] ADLs.xlsx
  iadl_file: data/wp-01/[Lawton] IADL.xlsx
  mapping_file: data/wp-02/FAST and ADL IADL mapping.xlsx

documents:
  - id: doc_001
    name: "The Dementia Guide"
    file_path: data/resources/the_dementia_guide.pdf
    source_organization: "Alzheimer's Society UK"
    target_audience: "Both"
    language: en

  - id: doc_002
    name: "Caring: A Practical Guide"
    file_path: data/resources/caring_practical_guide.pdf
    source_organization: "Alzheimer's Society UK"
    target_audience: "Caregiver"
    language: en

extraction:
  pdf_library: auto
  min_section_length: 50
  min_paragraph_length: 20
  extract_tips: true

annotation:
  # Use LLM-based annotation with LlamaCPP
  method: llm
  min_confidence: 0.3

# ============================================================================
# LlamaCPP Configuration (LOCAL - GGUF files)
# ============================================================================
llm:
  enabled: true
  provider: llamacpp

  # Path to GGUF model file
  # Download from: https://huggingface.co/TheBloke
  # Popular options:
  # - Llama-2-7B-Chat-GGUF
  # - Mistral-7B-Instruct-v0.2-GGUF
  # - TinyLlama-1.1B-Chat-v1.0-GGUF
  model_path: models/llama-2-7b-chat.Q4_K_M.gguf

  # Context window size
  n_ctx: 4096

  # GPU layers to offload (0 = CPU only, -1 = all layers)
  # Set higher for GPU acceleration
  n_gpu_layers: 0

  # No API key needed
  temperature: 0.3
  max_tokens: 2000

output:
  output_dir: output
  generate_knowledge_graph: true
  knowledge_graph_file: output/knowledge_graph.jsonld
  knowledge_graph_base_uri: "http://health-knowledge-recommender.org/kg/"
  include_reference_data: true
  generate_csv: true
  generate_json: false

logging:
  level: INFO
  log_file: logs/extraction.log
